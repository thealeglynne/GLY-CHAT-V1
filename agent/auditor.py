import os
import json
from datetime import datetime
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate

# ========================
# 1. Cargar entorno y API
# ========================
load_dotenv()
api_key = os.getenv('GROQ_API_KEY2')
hf_api_key = os.getenv('HUGGINGFACE_API_KEY2')

if not api_key:
    raise ValueError('No hay una API key v√°lida de Groq en el .env')

if not hf_api_key:
    raise ValueError('No hay una API key v√°lida de Hugging Face en el .env')

# ========================
# 2. Inicializar LLM principal (Groq)
# ========================
llm = ChatGroq(
    model="Llama-3.1-8B-Instant",
    api_key=api_key,
    temperature=0.7,
    max_tokens=1500
)

# ========================
# 2b. LLM de fallback Hugging Face v√≠a API
# ========================
def llm_huggingface_fallback(prompt_text: str) -> str:
    """
    Fallback a Hugging Face usando API Key
    """
    try:
        from transformers import pipeline

        generator = pipeline(
            "text-generation",
            model="tiiuae/falcon-7b-instruct",
            device=-1,
            use_auth_token=hf_api_key
        )

        output = generator(
            prompt_text,
            max_length=500,
            do_sample=True,
            top_p=0.95
        )
        return output[0]["generated_text"]

    except Exception as e:
        print("‚ùå Error fallback Hugging Face:", e)
        return "Lo siento, no pude generar la auditor√≠a."

# ========================
# 3. Prompt de auditor√≠a
# ========================
Prompt_estructura = """
[META]
Fecha del reporte: {fecha}
Tu meta es analizar el negocio del usuario usando la conversaci√≥n hist√≥rica.
Genera un documento de auditor√≠a profesional, corporativo y estructurado, centrado en identificar
c√≥mo las soluciones de automatizaci√≥n impulsadas por inteligencia artificial pueden integrarse
en los procesos, problemas o necesidades expresadas por el usuario.

El documento debe tener un enfoque estrat√©gico y t√©cnico, mostrando c√≥mo la IA puede
mejorar eficiencia, escalabilidad, comunicaci√≥n interna, toma de decisiones y reducci√≥n de tareas repetitivas.

Estructura el informe con los siguientes apartados:

1. Portada  
   - Incluye el nombre del usuario o empresa si se menciona, el auditor (GLY-IA), y la fecha.  

2. Resumen ejecutivo  
   - Resume brevemente la situaci√≥n actual del negocio y las oportunidades de automatizaci√≥n con IA detectadas.  

3. Alcance y objetivos  
   - Define los procesos o √°reas que se pueden beneficiar de la automatizaci√≥n seg√∫n el historial de conversaci√≥n.  

4. Metodolog√≠a  
   - Explica c√≥mo se analizaron los datos y c√≥mo se plantea identificar flujos automatizables usando modelos de lenguaje, agentes inteligentes, o integraci√≥n de sistemas.  

5. Procesos auditados y hallazgos  
   - Describe cada proceso o √°rea mencionada por el usuario.  
   - Detalla los puntos cr√≠ticos, tareas repetitivas o cuellos de botella y c√≥mo pueden automatizarse mediante IA (por ejemplo, agentes, APIs, flujos conversacionales o sistemas de orquestaci√≥n).  

6. Recomendaciones  
   - Prop√≥n estrategias concretas para aplicar IA en los flujos de trabajo del usuario.  
   - Menciona posibles arquitecturas, integraci√≥n de agentes, automatizaci√≥n de departamentos o conexi√≥n de datos empresariales.  

7. Conclusiones  
   - Sintetiza los beneficios esperados al implementar la automatizaci√≥n basada en IA y c√≥mo esto puede escalar el negocio.  

8. Anexos  
   - Incluye fragmentos relevantes de la conversaci√≥n que sirvan como evidencia o contexto.  

Cada apartado debe tener al menos un p√°rrafo completo, t√©cnico y contextual.  
No inventes informaci√≥n, usa √∫nicamente lo que el usuario comunic√≥ en el historial, extrapolando c√≥mo se podr√≠an aplicar soluciones inteligentes.

[ENTRADA DEL USUARIO]
Historial de conversaci√≥n: {historial}

Respuesta:
"""


prompt_template = PromptTemplate(
    input_variables=["historial", "fecha"],
    template=Prompt_estructura.strip()
)

# ========================
# 4. Funci√≥n para generar auditor√≠a por usuario
# ========================
def generar_auditoria(user_id: str):
    """
    Genera una auditor√≠a basada en el JSON correspondiente a un usuario espec√≠fico.
    Compatible con la estructura del main.py
    """
    json_path = os.path.join("conversaciones", f"conversacion_{user_id}.json")

    if not os.path.exists(json_path):
        raise FileNotFoundError(f"No se encontr√≥ la conversaci√≥n del usuario {user_id}")

    # Leer conversaci√≥n del usuario
    with open(json_path, "r", encoding="utf-8") as f:
        conversacion = json.load(f)

    if not conversacion:
        raise ValueError(f"La conversaci√≥n del usuario {user_id} est√° vac√≠a.")

    # Formatear conversaci√≥n para el prompt
    historial_texto = ""
    for intercambio in conversacion:
        historial_texto += f"Usuario: {intercambio.get('user', '')}\n"
        historial_texto += f"GLY-AI: {intercambio.get('ai', '')}\n"

    # Obtener fecha actual
    fecha_actual = datetime.now().strftime("%d/%m/%Y")

    # Crear prompt con fecha y conversaci√≥n
    prompt_text = prompt_template.format(historial=historial_texto, fecha=fecha_actual)

    # ===========================
    # Ejecutar LLM principal con fallback
    # ===========================
    try:
        respuesta = llm.invoke(prompt_text)
        texto_final = respuesta.content if hasattr(respuesta, "content") else str(respuesta)
    except Exception as e:
        print("‚ùå Error en Groq LLM:", e)
        texto_final = llm_huggingface_fallback(prompt_text)

    # ===========================
    # Guardar auditor√≠a generada en archivo separado
    # ===========================
    auditoria_path = os.path.join("conversaciones", f"auditoria_{user_id}.json")
    try:
        with open(auditoria_path, "w", encoding="utf-8") as f:
            json.dump({
                "user_id": user_id,
                "fecha": fecha_actual,
                "auditoria": texto_final
            }, f, ensure_ascii=False, indent=4)
        print(f"‚úÖ Auditor√≠a guardada en: {auditoria_path}")
    except Exception as e:
        print(f"‚ùå Error al guardar auditor√≠a de {user_id}:", e)

    return texto_final

# ========================
# 5. CLI opcional para pruebas
# ========================
if __name__ == "__main__":
    print("LLM Auditor√≠a iniciado")
    try:
        test_user = input("üß© Ingrese user_id para generar la auditor√≠a: ").strip()
        resultado = generar_auditoria(test_user)
        print("\n===== AUDITOR√çA =====\n")
        print(resultado)
        print("\n=====================\n")
    except Exception as e:
        print("‚ùå Error general:", e)
